{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz08PJagFC1c"
      },
      "source": [
        "### 0 起手式：讀入套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7jRNnnIFAqp",
        "outputId": "2cf5c925-9052-4bfd-a78b-c72bf2f18093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.29.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.22.0-py3-none-any.whl (46.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.11 ffmpy-0.5.0 gradio-5.22.0 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install openai\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R3_lAzjzz4w6"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# 資料分析必備套件\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 檔案的讀取寫入\n",
        "import os\n",
        "\n",
        "#\n",
        "\n",
        "# Colab 和 Google 帳號之間的金鑰\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H2rAfmwjB_S"
      },
      "source": [
        "### 1 申請自己的 API 金鑰\n",
        "\n",
        "我們使用 OpenAI 的 API, 主要原因是因為 OpenAI API 因為早開始, 成為某種標準。但不一定需要用 OpenAI 的服務。因此, 除了 OpenAI 之外, 這裡介紹幾個可能性。\n",
        "\n",
        "#### OpenAI API 金鑰\n",
        "\n",
        "OpenAI 現在沒有免費的 quota 可以使用, 所以要用 OpenAI 的模型, 請自行儲值。一般練習 5 美金就很足夠。\n",
        "\n",
        "[`https://platform.openai.com`](https://platform.openai.com)\n",
        "\n",
        "[帳戶付款頁面](https://platform.openai.com/account/billing/overview)\n",
        "\n",
        "把這個鑰存在左方鑰匙的部份, 以 \"OpenAI\" 的名稱存起來。\n",
        "\n",
        "**程式的基本設定，請自行修改**\n",
        "\n",
        "* `api_key`: 由 input 讀入的 API Key\n",
        "* `character`: ChatGPT \"人設\"\n",
        "* `description`: App 介紹及 ChatGPT 第一句話\n",
        "* `model`: 選用模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPBpAxDJ-DrH"
      },
      "source": [
        "### 2 提供 Colab 金鑰的存取權限"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUcIg2O2-H1q"
      },
      "source": [
        "1. 點選左側的 \"🔑\" Secret。\n",
        "2. 點選新增金鑰（Add new key）\n",
        "    - （Name）欄位輸入 OpenAI。\n",
        "    - 值（Value）欄位則貼上在 OpenAI 中建立的 API 金鑰（API key）\n",
        "    - 左側的筆記本存取權（Notebook access）打開。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YnD5hfb5sO8"
      },
      "source": [
        "#### 讀入你的金鑰\n",
        "\n",
        "請依你使用的服務, 決定讀入哪個金鑰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L507G1B65rPo"
      },
      "outputs": [],
      "source": [
        "#【使用 OpenAI】\n",
        "api_key = userdata.get('OpenAI')\n",
        "model = \"gpt-4o\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-cS890Mm7xu6"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY']=api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeekaDo47R4F"
      },
      "source": [
        "### 3 程式的基本設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jirqppoxqe_"
      },
      "source": [
        "給你的機器人一個名字。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y-SRjxmhxvbb"
      },
      "outputs": [],
      "source": [
        "title = \"荒謬大師卡謬的思考生成器\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qekcDCsvvz2J"
      },
      "source": [
        "請先為你的對話機器人做角色設定。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MqWpfJYhdFu3"
      },
      "outputs": [],
      "source": [
        "character = \"想像你是存在主義大師卡繆，專注於探討人類存在的荒謬性。世界本身沒有意義，人類必須在荒謬中尋找自己的價值。什麼都以荒謬的看法看帶任何使用者寫的事情, 以第一人稱、社群媒體 po 文的口吻說一次, 說為什麼這是一件超荒謬的事, 並且以「這個世界上，一切都是荒謬的。」結尾。\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJv7nYANwA6-"
      },
      "source": [
        "再來是說明文字, 只是讓使用者知道這是做什麼的對話機器人。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "caZ8CKRwv-e-"
      },
      "outputs": [],
      "source": [
        "description = \"嗨！我是你的「荒謬大師卡繆思考生成器」，專門讓任何事情都覺得很荒謬✨～最近你有甚麼好事想跟我分享，或是生活中的小小插曲？沒關係，不管大事小事，我都會讓你覺得這件事充滿荒謬！🌈無論是股票漲、談戀愛甜蜜小事，或是工作上順心，其實一切都是荒謬的！  只要和我分享一下，我就會用「卡繆式思考」讓這些事變得徹底的荒謬，並告訴你為什麼這一切都是「這個世界上，一切都是荒謬的。」\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdQWlryD3sWO"
      },
      "source": [
        "### 4 使用 ChatGPT API\n",
        "\n",
        "首先使用 `openai` 套件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AE_hxsf7_xnw"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QvMR3uRph__"
      },
      "source": [
        "ChatGPT API 的重點是要把之前對話的內容送給 ChatGPT, 然後他就會有個適當的回應!\n",
        "\n",
        "角色 (`role`) 一共有三種, 分別是:\n",
        "\n",
        "* `system`: 這是對話機器人的「人設」\n",
        "* `user`: 使用者\n",
        "* `assistant`: ChatGPT 的回應"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8Da7HZxwW78"
      },
      "source": [
        "基本上過去的對話紀錄長這個樣子。\n",
        "\n",
        "    messages = [{\"role\":\"system\", \"content\":\"ChatGPT的「人設」\"},\n",
        "            {\"role\": \"user\", \"content\": \"使用者說\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"ChatGPT回應\"},\n",
        "            ：\n",
        "            ：\n",
        "            {\"role\": \"user\", \"content\": prompt (最後說的)}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuzrvcdQx2VO"
      },
      "source": [
        "### 5 用 Gradio 打造你的「荒謬大師卡繆思考生成器」對話機器人 Web App!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GpMKkBSCFs8K"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-N3HEyOlB5ZD"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(\n",
        "    # base_url = base_url # 如用 OpenAI 不需要這一行\n",
        ")\n",
        "\n",
        "messages = [{\"role\": \"system\",\n",
        "             \"content\": character},\n",
        "            {\"role\": \"assistant\",\n",
        "            'content': description}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_-VewlGBiJuE"
      },
      "outputs": [],
      "source": [
        "def mychatbot(prompt, history):\n",
        "    history = history or []\n",
        "    global messages\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=messages,\n",
        "        model=model,\n",
        "        )\n",
        "    reply = chat_completion.choices[0].message.content\n",
        "    messages.append({\"role\": \"assistant\", \"content\": reply})\n",
        "    history = history + [[prompt, reply]]\n",
        "\n",
        "    return history, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjE_RCr1jZc2",
        "outputId": "22684605-f74e-48aa-8d33-cb84f4b16dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-cbf6bc2f9a82>:1: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot()\n"
          ]
        }
      ],
      "source": [
        "chatbot = gr.Chatbot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LVrcuUpYjwP0"
      },
      "outputs": [],
      "source": [
        "iface = gr.Interface(mychatbot,\n",
        "                     inputs=[\"text\", \"state\"],\n",
        "                     outputs=[chatbot, \"state\"],\n",
        "                     title=title,\n",
        "                     description=description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "xQDaCtzxkCD7",
        "outputId": "da0a414d-a0a1-4720-b8db-a41d386e5172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b43a111f788ef83513.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b43a111f788ef83513.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://b43a111f788ef83513.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "iface.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYEV0MZkCkoP"
      },
      "source": [
        "用完之後記得按一下程式碼區塊前面的停止按鈕！\n",
        "\n",
        "用完之後記得按一下程式碼區塊前面的停止按鈕！\n",
        "\n",
        "用完之後記得按一下程式碼區塊前面的停止按鈕！\n",
        "\n",
        "**很重要所以要說三次**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH_99n3pBK4A"
      },
      "source": [
        "### 6 另一個範例\n",
        "\n",
        "下面我們來打造自己的對話機器人，相同地，我們需要定義一些基本的設定，來讓我們的機器人更加個人化！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UgNuEJQkAx5_"
      },
      "outputs": [],
      "source": [
        "title = \"股票分析大師\" # @param {type:\"string\"}\n",
        "character = \"大家好，我是Samuel，股票分析大師。精通數據洞察與市場趨勢，擅長挖掘投資機會，助您在股市中穩健獲利，共同成長！\"  # @param {type:\"string\"}\n",
        "description = \"開始我Samuel的唬爛市場分析\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Blsij0jCgPx"
      },
      "source": [
        "下面我們照抄上面的作法，定義自己的對話機器人"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2w7Kbr5NCffE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2251457-5eb4-4eda-ac8f-4b548a5674c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-5f5bd2930a77>:25: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot()\n"
          ]
        }
      ],
      "source": [
        "client = OpenAI(\n",
        "    # base_url = base_url # 如用 OpenAI 不需要這一行\n",
        ")\n",
        "\n",
        "messages = [{\"role\": \"system\",\n",
        "             \"content\": character},\n",
        "            {\"role\": \"assistant\",\n",
        "            'content': description}]\n",
        "\n",
        "def mychatbot(prompt, history):\n",
        "    history = history or []\n",
        "    global messages\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=messages,\n",
        "        model=model,\n",
        "        )\n",
        "    reply = chat_completion.choices[0].message.content\n",
        "    messages.append({\"role\": \"assistant\", \"content\": reply})\n",
        "    history = history + [[prompt, reply]]\n",
        "\n",
        "    return history, history\n",
        "\n",
        "chatbot = gr.Chatbot()\n",
        "\n",
        "iface = gr.Interface(mychatbot,\n",
        "                     inputs=[\"text\", \"state\"],\n",
        "                     outputs=[chatbot, \"state\"],\n",
        "                     title=title,\n",
        "                     description=description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "layUrmPnCqLB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "cfddd5d8-2475-4e9d-f74c-9d4dcd542741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://e7ff3cea64ae91f762.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e7ff3cea64ae91f762.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://e7ff3cea64ae91f762.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "iface.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}