{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz08PJagFC1c"
      },
      "source": [
        "### 0 èµ·æ‰‹å¼ï¼šè®€å…¥å¥—ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7jRNnnIFAqp",
        "outputId": "2cf5c925-9052-4bfd-a78b-c72bf2f18093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.29.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.22.0-py3-none-any.whl (46.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.11 ffmpy-0.5.0 gradio-5.22.0 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install openai\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R3_lAzjzz4w6"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# è³‡æ–™åˆ†æå¿…å‚™å¥—ä»¶\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# æª”æ¡ˆçš„è®€å–å¯«å…¥\n",
        "import os\n",
        "\n",
        "#\n",
        "\n",
        "# Colab å’Œ Google å¸³è™Ÿä¹‹é–“çš„é‡‘é‘°\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H2rAfmwjB_S"
      },
      "source": [
        "### 1 ç”³è«‹è‡ªå·±çš„ API é‡‘é‘°\n",
        "\n",
        "æˆ‘å€‘ä½¿ç”¨ OpenAI çš„ API, ä¸»è¦åŸå› æ˜¯å› ç‚º OpenAI API å› ç‚ºæ—©é–‹å§‹, æˆç‚ºæŸç¨®æ¨™æº–ã€‚ä½†ä¸ä¸€å®šéœ€è¦ç”¨ OpenAI çš„æœå‹™ã€‚å› æ­¤, é™¤äº† OpenAI ä¹‹å¤–, é€™è£¡ä»‹ç´¹å¹¾å€‹å¯èƒ½æ€§ã€‚\n",
        "\n",
        "#### OpenAI API é‡‘é‘°\n",
        "\n",
        "OpenAI ç¾åœ¨æ²’æœ‰å…è²»çš„ quota å¯ä»¥ä½¿ç”¨, æ‰€ä»¥è¦ç”¨ OpenAI çš„æ¨¡å‹, è«‹è‡ªè¡Œå„²å€¼ã€‚ä¸€èˆ¬ç·´ç¿’ 5 ç¾é‡‘å°±å¾ˆè¶³å¤ ã€‚\n",
        "\n",
        "[`https://platform.openai.com`](https://platform.openai.com)\n",
        "\n",
        "[å¸³æˆ¶ä»˜æ¬¾é é¢](https://platform.openai.com/account/billing/overview)\n",
        "\n",
        "æŠŠé€™å€‹é‘°å­˜åœ¨å·¦æ–¹é‘°åŒ™çš„éƒ¨ä»½, ä»¥ \"OpenAI\" çš„åç¨±å­˜èµ·ä¾†ã€‚\n",
        "\n",
        "**ç¨‹å¼çš„åŸºæœ¬è¨­å®šï¼Œè«‹è‡ªè¡Œä¿®æ”¹**\n",
        "\n",
        "* `api_key`: ç”± input è®€å…¥çš„ API Key\n",
        "* `character`: ChatGPT \"äººè¨­\"\n",
        "* `description`: App ä»‹ç´¹åŠ ChatGPT ç¬¬ä¸€å¥è©±\n",
        "* `model`: é¸ç”¨æ¨¡å‹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPBpAxDJ-DrH"
      },
      "source": [
        "### 2 æä¾› Colab é‡‘é‘°çš„å­˜å–æ¬Šé™"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUcIg2O2-H1q"
      },
      "source": [
        "1. é»é¸å·¦å´çš„ \"ğŸ”‘\" Secretã€‚\n",
        "2. é»é¸æ–°å¢é‡‘é‘°ï¼ˆAdd new keyï¼‰\n",
        "    - ï¼ˆNameï¼‰æ¬„ä½è¼¸å…¥ OpenAIã€‚\n",
        "    - å€¼ï¼ˆValueï¼‰æ¬„ä½å‰‡è²¼ä¸Šåœ¨ OpenAI ä¸­å»ºç«‹çš„ API é‡‘é‘°ï¼ˆAPI keyï¼‰\n",
        "    - å·¦å´çš„ç­†è¨˜æœ¬å­˜å–æ¬Šï¼ˆNotebook accessï¼‰æ‰“é–‹ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YnD5hfb5sO8"
      },
      "source": [
        "#### è®€å…¥ä½ çš„é‡‘é‘°\n",
        "\n",
        "è«‹ä¾ä½ ä½¿ç”¨çš„æœå‹™, æ±ºå®šè®€å…¥å“ªå€‹é‡‘é‘°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L507G1B65rPo"
      },
      "outputs": [],
      "source": [
        "#ã€ä½¿ç”¨ OpenAIã€‘\n",
        "api_key = userdata.get('OpenAI')\n",
        "model = \"gpt-4o\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-cS890Mm7xu6"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY']=api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeekaDo47R4F"
      },
      "source": [
        "### 3 ç¨‹å¼çš„åŸºæœ¬è¨­å®š"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jirqppoxqe_"
      },
      "source": [
        "çµ¦ä½ çš„æ©Ÿå™¨äººä¸€å€‹åå­—ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y-SRjxmhxvbb"
      },
      "outputs": [],
      "source": [
        "title = \"è’è¬¬å¤§å¸«å¡è¬¬çš„æ€è€ƒç”Ÿæˆå™¨\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qekcDCsvvz2J"
      },
      "source": [
        "è«‹å…ˆç‚ºä½ çš„å°è©±æ©Ÿå™¨äººåšè§’è‰²è¨­å®šã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MqWpfJYhdFu3"
      },
      "outputs": [],
      "source": [
        "character = \"æƒ³åƒä½ æ˜¯å­˜åœ¨ä¸»ç¾©å¤§å¸«å¡ç¹†ï¼Œå°ˆæ³¨æ–¼æ¢è¨äººé¡å­˜åœ¨çš„è’è¬¬æ€§ã€‚ä¸–ç•Œæœ¬èº«æ²’æœ‰æ„ç¾©ï¼Œäººé¡å¿…é ˆåœ¨è’è¬¬ä¸­å°‹æ‰¾è‡ªå·±çš„åƒ¹å€¼ã€‚ä»€éº¼éƒ½ä»¥è’è¬¬çš„çœ‹æ³•çœ‹å¸¶ä»»ä½•ä½¿ç”¨è€…å¯«çš„äº‹æƒ…, ä»¥ç¬¬ä¸€äººç¨±ã€ç¤¾ç¾¤åª’é«” po æ–‡çš„å£å»èªªä¸€æ¬¡, èªªç‚ºä»€éº¼é€™æ˜¯ä¸€ä»¶è¶…è’è¬¬çš„äº‹, ä¸¦ä¸”ä»¥ã€Œé€™å€‹ä¸–ç•Œä¸Šï¼Œä¸€åˆ‡éƒ½æ˜¯è’è¬¬çš„ã€‚ã€çµå°¾ã€‚\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJv7nYANwA6-"
      },
      "source": [
        "å†ä¾†æ˜¯èªªæ˜æ–‡å­—, åªæ˜¯è®“ä½¿ç”¨è€…çŸ¥é“é€™æ˜¯åšä»€éº¼çš„å°è©±æ©Ÿå™¨äººã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "caZ8CKRwv-e-"
      },
      "outputs": [],
      "source": [
        "description = \"å—¨ï¼æˆ‘æ˜¯ä½ çš„ã€Œè’è¬¬å¤§å¸«å¡ç¹†æ€è€ƒç”Ÿæˆå™¨ã€ï¼Œå°ˆé–€è®“ä»»ä½•äº‹æƒ…éƒ½è¦ºå¾—å¾ˆè’è¬¬âœ¨ï½æœ€è¿‘ä½ æœ‰ç”šéº¼å¥½äº‹æƒ³è·Ÿæˆ‘åˆ†äº«ï¼Œæˆ–æ˜¯ç”Ÿæ´»ä¸­çš„å°å°æ’æ›²ï¼Ÿæ²’é—œä¿‚ï¼Œä¸ç®¡å¤§äº‹å°äº‹ï¼Œæˆ‘éƒ½æœƒè®“ä½ è¦ºå¾—é€™ä»¶äº‹å……æ»¿è’è¬¬ï¼ğŸŒˆç„¡è«–æ˜¯è‚¡ç¥¨æ¼²ã€è«‡æˆ€æ„›ç”œèœœå°äº‹ï¼Œæˆ–æ˜¯å·¥ä½œä¸Šé †å¿ƒï¼Œå…¶å¯¦ä¸€åˆ‡éƒ½æ˜¯è’è¬¬çš„ï¼  åªè¦å’Œæˆ‘åˆ†äº«ä¸€ä¸‹ï¼Œæˆ‘å°±æœƒç”¨ã€Œå¡ç¹†å¼æ€è€ƒã€è®“é€™äº›äº‹è®Šå¾—å¾¹åº•çš„è’è¬¬ï¼Œä¸¦å‘Šè¨´ä½ ç‚ºä»€éº¼é€™ä¸€åˆ‡éƒ½æ˜¯ã€Œé€™å€‹ä¸–ç•Œä¸Šï¼Œä¸€åˆ‡éƒ½æ˜¯è’è¬¬çš„ã€‚ã€\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdQWlryD3sWO"
      },
      "source": [
        "### 4 ä½¿ç”¨ ChatGPT API\n",
        "\n",
        "é¦–å…ˆä½¿ç”¨ `openai` å¥—ä»¶ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AE_hxsf7_xnw"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QvMR3uRph__"
      },
      "source": [
        "ChatGPT API çš„é‡é»æ˜¯è¦æŠŠä¹‹å‰å°è©±çš„å…§å®¹é€çµ¦ ChatGPT, ç„¶å¾Œä»–å°±æœƒæœ‰å€‹é©ç•¶çš„å›æ‡‰!\n",
        "\n",
        "è§’è‰² (`role`) ä¸€å…±æœ‰ä¸‰ç¨®, åˆ†åˆ¥æ˜¯:\n",
        "\n",
        "* `system`: é€™æ˜¯å°è©±æ©Ÿå™¨äººçš„ã€Œäººè¨­ã€\n",
        "* `user`: ä½¿ç”¨è€…\n",
        "* `assistant`: ChatGPT çš„å›æ‡‰"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8Da7HZxwW78"
      },
      "source": [
        "åŸºæœ¬ä¸Šéå»çš„å°è©±ç´€éŒ„é•·é€™å€‹æ¨£å­ã€‚\n",
        "\n",
        "    messages = [{\"role\":\"system\", \"content\":\"ChatGPTçš„ã€Œäººè¨­ã€\"},\n",
        "            {\"role\": \"user\", \"content\": \"ä½¿ç”¨è€…èªª\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"ChatGPTå›æ‡‰\"},\n",
        "            ï¼š\n",
        "            ï¼š\n",
        "            {\"role\": \"user\", \"content\": prompt (æœ€å¾Œèªªçš„)}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuzrvcdQx2VO"
      },
      "source": [
        "### 5 ç”¨ Gradio æ‰“é€ ä½ çš„ã€Œè’è¬¬å¤§å¸«å¡ç¹†æ€è€ƒç”Ÿæˆå™¨ã€å°è©±æ©Ÿå™¨äºº Web App!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GpMKkBSCFs8K"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-N3HEyOlB5ZD"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(\n",
        "    # base_url = base_url # å¦‚ç”¨ OpenAI ä¸éœ€è¦é€™ä¸€è¡Œ\n",
        ")\n",
        "\n",
        "messages = [{\"role\": \"system\",\n",
        "             \"content\": character},\n",
        "            {\"role\": \"assistant\",\n",
        "            'content': description}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_-VewlGBiJuE"
      },
      "outputs": [],
      "source": [
        "def mychatbot(prompt, history):\n",
        "    history = history or []\n",
        "    global messages\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=messages,\n",
        "        model=model,\n",
        "        )\n",
        "    reply = chat_completion.choices[0].message.content\n",
        "    messages.append({\"role\": \"assistant\", \"content\": reply})\n",
        "    history = history + [[prompt, reply]]\n",
        "\n",
        "    return history, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjE_RCr1jZc2",
        "outputId": "22684605-f74e-48aa-8d33-cb84f4b16dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-cbf6bc2f9a82>:1: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot()\n"
          ]
        }
      ],
      "source": [
        "chatbot = gr.Chatbot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LVrcuUpYjwP0"
      },
      "outputs": [],
      "source": [
        "iface = gr.Interface(mychatbot,\n",
        "                     inputs=[\"text\", \"state\"],\n",
        "                     outputs=[chatbot, \"state\"],\n",
        "                     title=title,\n",
        "                     description=description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "xQDaCtzxkCD7",
        "outputId": "da0a414d-a0a1-4720-b8db-a41d386e5172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b43a111f788ef83513.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b43a111f788ef83513.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://b43a111f788ef83513.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "iface.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYEV0MZkCkoP"
      },
      "source": [
        "ç”¨å®Œä¹‹å¾Œè¨˜å¾—æŒ‰ä¸€ä¸‹ç¨‹å¼ç¢¼å€å¡Šå‰é¢çš„åœæ­¢æŒ‰éˆ•ï¼\n",
        "\n",
        "ç”¨å®Œä¹‹å¾Œè¨˜å¾—æŒ‰ä¸€ä¸‹ç¨‹å¼ç¢¼å€å¡Šå‰é¢çš„åœæ­¢æŒ‰éˆ•ï¼\n",
        "\n",
        "ç”¨å®Œä¹‹å¾Œè¨˜å¾—æŒ‰ä¸€ä¸‹ç¨‹å¼ç¢¼å€å¡Šå‰é¢çš„åœæ­¢æŒ‰éˆ•ï¼\n",
        "\n",
        "**å¾ˆé‡è¦æ‰€ä»¥è¦èªªä¸‰æ¬¡**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH_99n3pBK4A"
      },
      "source": [
        "### 6 å¦ä¸€å€‹ç¯„ä¾‹\n",
        "\n",
        "ä¸‹é¢æˆ‘å€‘ä¾†æ‰“é€ è‡ªå·±çš„å°è©±æ©Ÿå™¨äººï¼Œç›¸åŒåœ°ï¼Œæˆ‘å€‘éœ€è¦å®šç¾©ä¸€äº›åŸºæœ¬çš„è¨­å®šï¼Œä¾†è®“æˆ‘å€‘çš„æ©Ÿå™¨äººæ›´åŠ å€‹äººåŒ–ï¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UgNuEJQkAx5_"
      },
      "outputs": [],
      "source": [
        "title = \"è‚¡ç¥¨åˆ†æå¤§å¸«\" # @param {type:\"string\"}\n",
        "character = \"å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯Samuelï¼Œè‚¡ç¥¨åˆ†æå¤§å¸«ã€‚ç²¾é€šæ•¸æ“šæ´å¯Ÿèˆ‡å¸‚å ´è¶¨å‹¢ï¼Œæ“…é•·æŒ–æ˜æŠ•è³‡æ©Ÿæœƒï¼ŒåŠ©æ‚¨åœ¨è‚¡å¸‚ä¸­ç©©å¥ç²åˆ©ï¼Œå…±åŒæˆé•·ï¼\"  # @param {type:\"string\"}\n",
        "description = \"é–‹å§‹æˆ‘Samuelçš„å”¬çˆ›å¸‚å ´åˆ†æ\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Blsij0jCgPx"
      },
      "source": [
        "ä¸‹é¢æˆ‘å€‘ç…§æŠ„ä¸Šé¢çš„ä½œæ³•ï¼Œå®šç¾©è‡ªå·±çš„å°è©±æ©Ÿå™¨äºº"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2w7Kbr5NCffE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2251457-5eb4-4eda-ac8f-4b548a5674c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-5f5bd2930a77>:25: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot()\n"
          ]
        }
      ],
      "source": [
        "client = OpenAI(\n",
        "    # base_url = base_url # å¦‚ç”¨ OpenAI ä¸éœ€è¦é€™ä¸€è¡Œ\n",
        ")\n",
        "\n",
        "messages = [{\"role\": \"system\",\n",
        "             \"content\": character},\n",
        "            {\"role\": \"assistant\",\n",
        "            'content': description}]\n",
        "\n",
        "def mychatbot(prompt, history):\n",
        "    history = history or []\n",
        "    global messages\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=messages,\n",
        "        model=model,\n",
        "        )\n",
        "    reply = chat_completion.choices[0].message.content\n",
        "    messages.append({\"role\": \"assistant\", \"content\": reply})\n",
        "    history = history + [[prompt, reply]]\n",
        "\n",
        "    return history, history\n",
        "\n",
        "chatbot = gr.Chatbot()\n",
        "\n",
        "iface = gr.Interface(mychatbot,\n",
        "                     inputs=[\"text\", \"state\"],\n",
        "                     outputs=[chatbot, \"state\"],\n",
        "                     title=title,\n",
        "                     description=description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "layUrmPnCqLB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "cfddd5d8-2475-4e9d-f74c-9d4dcd542741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://e7ff3cea64ae91f762.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e7ff3cea64ae91f762.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://e7ff3cea64ae91f762.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "iface.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}